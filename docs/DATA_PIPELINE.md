# üìä Data Pipeline & Large-Scale Data Handling

## Vue d'ensemble

Le syst√®me Digital Twin WMS a √©t√© am√©lior√© avec un **pipeline de donn√©es robuste** capable de g√©rer de grandes quantit√©s de donn√©es avec des performances optimales.

## üöÄ Nouvelles fonctionnalit√©s

### 1. **Data Pipeline Module** (`data-pipeline.js`)

Module centralis√© pour la gestion des donn√©es avec :

- ‚úÖ **IndexedDB Storage** : Stockage persistant dans le navigateur (pas de limite de 5MB comme localStorage)
- ‚úÖ **Batch Processing** : Traitement par lots pour les gros volumes (1000 items/batch)
- ‚úÖ **Caching** : Mise en cache en m√©moire pour acc√®s ultra-rapide
- ‚úÖ **Indexed Queries** : Requ√™tes optimis√©es avec indexes (aisle, rack, level, category, fillLevel)
- ‚úÖ **Advanced Filtering** : Filtrage multi-crit√®res performant
- ‚úÖ **Data Aggregation** : Calculs statistiques (count, sum, avg, min, max, median)
- ‚úÖ **CSV Import/Export** : Import et export asynchrone de fichiers CSV
- ‚úÖ **Pagination** : D√©coupage des donn√©es pour affichage progressif

### 2. **Virtual Scroller** (`virtual-scroller.js`)

Rendu optimis√© pour les grandes listes :

- ‚úÖ **VirtualScroller** : Affiche uniquement les √©l√©ments visibles (+ buffer)
- ‚úÖ **VirtualGrid** : Grille 2D virtualis√©e pour la vue entrep√¥t
- ‚úÖ **Performance** : Peut g√©rer des listes de 100 000+ items sans ralentissement
- ‚úÖ **Smooth Scrolling** : D√©filement fluide m√™me avec de grandes quantit√©s de donn√©es

## üì¶ Capacit√©s de traitement

| Fonctionnalit√© | Avant | Apr√®s |
|----------------|-------|-------|
| **Stockage max** | 5-10 MB (localStorage) | ~500 MB+ (IndexedDB) |
| **Items affichables** | 320 (10 all√©es √ó 8 racks √ó 4 niveaux) | Illimit√© (virtuel) |
| **Performance CSV** | Synchrone, bloque l'UI | Asynchrone, avec progr√®s |
| **Filtrage** | O(n) simple | O(log n) avec indexes |
| **Export donn√©es** | Manuel | Automatique CSV |
| **Persistence** | localStorage | IndexedDB + Cache |

## üîß Utilisation

### Initialisation du Data Pipeline

```javascript
// Automatiquement initialis√© dans chaque page
await dataPipeline.initDB();
```

### Sauvegarder des donn√©es

```javascript
// Sauvegarder des donn√©es (avec batch processing)
await dataPipeline.saveData(myData, 'stockData');

// Exemple avec 10,000 items
const bigData = generateBigDataset(10000);
await dataPipeline.saveData(bigData, 'stockData');
// ‚úÖ Sauvegarde par lots de 1000 items
```

### Charger des donn√©es

```javascript
// Charger depuis IndexedDB (avec cache)
const data = await dataPipeline.loadData('stockData');

// Premier appel : charge depuis IndexedDB
// Appels suivants : charge depuis cache (ultra-rapide)
```

### Filtrer des donn√©es

```javascript
// Filtrage simple
const filtered = await dataPipeline.filterData(data, {
    aisle: 2,
    level: 3
});

// Filtrage avanc√© avec plages
const filtered = await dataPipeline.filterData(data, {
    aisle: [1, 2, 3],  // Plusieurs valeurs
    fill_level: { min: 50, max: 100 }  // Plage
});
```

### Agr√©gation de donn√©es

```javascript
// Agr√©ger par all√©e
const byAisle = dataPipeline.aggregate(data, 'aisle', {
    fill_level: 'avg',    // Moyenne de remplissage
    id: 'count'           // Nombre d'items
});

// R√©sultat : 
// [
//   { aisle: 1, fill_level_avg: 65, id_count: 20 },
//   { aisle: 2, fill_level_avg: 72, id_count: 20 },
//   ...
// ]
```

### Calculer des statistiques

```javascript
const stats = dataPipeline.calculateStats(data, 'fill_level');

// R√©sultat :
// {
//   count: 60,
//   sum: 3780,
//   avg: 63,
//   min: 0,
//   max: 100,
//   median: 65
// }
```

### Import CSV

```javascript
// Import asynchrone avec progression
const data = await dataPipeline.parseCSV(file);
console.log(`Parsed ${data.length} rows`);

// Progression affich√©e automatiquement tous les 1000 lignes
```

### Export CSV

```javascript
// Exporter les donn√©es filtr√©es
dataPipeline.exportToCSV(filteredData, 'warehouse-export.csv');
```

### Pagination

```javascript
// Paginer les r√©sultats
const page1 = dataPipeline.paginate(data, 1, 20);

// R√©sultat :
// {
//   data: [...20 items...],
//   page: 1,
//   pageSize: 20,
//   totalPages: 150,
//   totalItems: 3000
// }
```

## üéØ Cas d'usage

### G√©rer un entrep√¥t de 1000 racks

```javascript
// G√©n√©rer 1000 racks √ó 4 niveaux = 4000 emplacements
const bigWarehouse = [];
for (let aisle = 1; aisle <= 100; aisle++) {
    for (let rack = 1; rack <= 10; rack++) {
        for (let level = 1; level <= 4; level++) {
            bigWarehouse.push({
                aisle, rack, level,
                sku: `SKU-${aisle}${rack}${level}`,
                fill_level: Math.floor(Math.random() * 101)
            });
        }
    }
}

// Sauvegarder (trait√© par lots)
await dataPipeline.saveData(bigWarehouse, 'stockData');

// Filtrer rapidement
const aisle5 = await dataPipeline.filterData(bigWarehouse, { aisle: 5 });

// Afficher avec virtualisation (uniquement les items visibles)
virtualGrid.setData(aisle5);
```

### Import CSV de 50 000 lignes

```javascript
// Le fichier est trait√© de mani√®re asynchrone
const csvData = await dataPipeline.parseCSV(largeFile);
// ‚úÖ Import progressif avec logs tous les 1000 lignes

// Sauvegarder dans IndexedDB
await dataPipeline.saveData(csvData, 'stockData');
// ‚úÖ Sauvegarde par lots de 1000 items

// Total : 50 000 lignes trait√©es en ~2-3 secondes
```

## üìä M√©triques de performance

Le syst√®me affiche automatiquement les m√©triques dans la console :

```javascript
üìä Performance Metrics: {
  loadTime: '156ms',      // Temps de chargement
  renderTime: '42ms',     // Temps de rendu
  filterTime: '12ms',     // Temps de filtrage
  itemCount: 4000,        // Nombre d'items
  memoryUsage: '45MB'     // Utilisation m√©moire
}
```

## üîí Persistence des donn√©es

Les donn√©es sont automatiquement sauvegard√©es dans IndexedDB et persistent :
- ‚úÖ Entre les sessions (fermeture/r√©ouverture du navigateur)
- ‚úÖ Entre les pages (index.html, warehouse-2d.html, stock-analysis.html)
- ‚úÖ Apr√®s un rafra√Æchissement (F5)

## üóëÔ∏è Nettoyage des donn√©es

```javascript
// Effacer le cache
dataPipeline.clearCache();

// Effacer toutes les donn√©es
await dataPipeline.clearDatabase('stockData');
```

## üé® Int√©gration dans l'interface

### Warehouse 2D
- Import CSV : Utilise `dataPipeline.parseCSV()`
- Sauvegarde auto : Donn√©es sauv√©es dans IndexedDB
- Filtrage : Utilise `dataPipeline.filterData()`
- Export : Bouton pour exporter en CSV

### Stock Analysis
- Chargement : Depuis IndexedDB (avec fallback localStorage)
- Tableaux : Pagination avec `dataPipeline.paginate()`
- Statistiques : Utilise `dataPipeline.calculateStats()`
- Graphiques : Donn√©es agr√©g√©es avec `dataPipeline.aggregate()`

## üöÄ Performance Tips

1. **Utilisez les index** : Les requ√™tes sur `aisle`, `rack`, `level`, `category`, `fill_level` sont optimis√©es
2. **Activez le cache** : Le cache acc√©l√®re les acc√®s r√©p√©t√©s aux m√™mes donn√©es
3. **Filtrez avant de paginer** : Filtrez d'abord, puis paginez le r√©sultat
4. **Utilisez la virtualisation** : Pour afficher de grandes listes (>100 items)
5. **Batch processing** : Les grosses op√©rations sont automatiquement trait√©es par lots

## üîç Debugging

```javascript
// Afficher les m√©triques
displayPerformanceMetrics();

// Voir les donn√©es en cache
console.log(dataPipeline.cache);

// Voir les statistiques agr√©g√©es
const stats = await getAggregatedStats();
console.log(stats);
```

## üìù Format CSV attendu

```csv
aisle,rack,level,sku,product_name,fill_level
1,1,1,SKU-001,Product A,85
1,1,2,SKU-002,Product B,45
1,1,3,SKU-003,Product C,0
...
```

Colonnes accept√©es (alias) :
- `aisle` ou `all√©e`
- `rack`
- `level` ou `niveau`
- `sku` ou `r√©f√©rence`
- `product_name` ou `produit`
- `fill_level` ou `remplissage`

## ‚ú® Avantages

| Avantage | D√©tail |
|----------|--------|
| **Scalabilit√©** | G√©rez des milliers d'emplacements sans probl√®me |
| **Performance** | Rendu optimis√© avec virtualisation |
| **Persistence** | Donn√©es sauv√©es automatiquement |
| **Flexibilit√©** | Import/Export CSV facile |
| **Robustesse** | Traitement asynchrone, pas de blocage UI |
| **Analytics** | Statistiques et agr√©gations int√©gr√©es |

---

**Cr√©√© pour le projet Digital Twin WMS**  
*G√©rez votre entrep√¥t √† grande √©chelle avec confiance* üöÄ
